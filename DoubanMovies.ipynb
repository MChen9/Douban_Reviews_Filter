{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from urllib import request\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, datetime\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import MySQLdb\n",
    "from datetime import date\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Login(url, username, password):\n",
    "    driver = webdriver.Chrome(executable_path=\n",
    "                              r'/Users/mchen/Documents/18FallCourses/Independent Study/Codes/Data/chromedriver')\n",
    "    driver.get(url)\n",
    "    driver.find_element_by_id('email').send_keys(username)\n",
    "    driver.find_element_by_id('password').send_keys(password)\n",
    "    try:\n",
    "        driver.find_element_by_id('captcha_field').send_keys(input('Verify Code:'))\n",
    "        driver.find_element_by_id('captcha_field').submit()\n",
    "    except:\n",
    "        driver.find_element_by_id('password').submit()\n",
    "    req = requests.Session()\n",
    "    cookies = driver.get_cookies()\n",
    "    for cookie in cookies:\n",
    "        req.cookies.set(cookie['name'], cookie['value'])\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 Firefox/2.0.0.11'}\n",
    "    req.headers = headers\n",
    "\n",
    "    return req, driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Login function to mimic web surfing behaviors such as opening web brower and loging in. For further usage, storing cookies by using cookies.set(), drivers is like Chrome, storing all information we need, and can be used for further searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeSoup(req, url):\n",
    "    soup = BeautifulSoup(req.get(url).content, 'html.parser', from_encoding='utf-8')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to use Beautifulsoup to parse websites, which is called make soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReplacePounctuation(pattern, sentence):\n",
    "    for i in pattern:\n",
    "        sentence = sentence.replace(i, ' ')\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to replace certain pounctuation marks, especially some marks can be misunderstanded by Python, using replace()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewContent():\n",
    "    def __init__(self, tag):\n",
    "        self.tag = tag\n",
    "        self.ReviewID = tag.input['value']\n",
    "        self.UserName = tag.a['title']\n",
    "        self.UserUrl = tag.a['href']\n",
    "        self.Votes = tag.find('span', class_='votes').text\n",
    "        self.RateStars = tag.find('span', class_='rating')['class'][0][-2]\n",
    "        self.Reviews = tag.find_all('span', class_='short')[0].text\n",
    "        self.Times = tag.find('span', class_='comment-time')['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class to store critical features of reviews, the input is the output of making soup, which is a specific data structure made by Beautifulsoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserProfile():\n",
    "    def __init__(self, req, url):\n",
    "        self.req = req\n",
    "        self.url = url\n",
    "        self.soup = MakeSoup(req, url)\n",
    "\n",
    "    def basic_info(self):\n",
    "        self.username = self.soup.find('div', class_='info').h1.text.split('\\n')[1].split(' ')[-1]\n",
    "        self.userid = self.soup.find('div', class_='user-info').find('div', class_='pl').text.split(' ')[0]\n",
    "        return self\n",
    "\n",
    "    def user_intro(self):\n",
    "        pattern = '‘’！——+|、·。/？；：“”「」【】=-》《～@#¥%……&*（），:;\\'.,\\%'\n",
    "        self.intro = ReplacePounctuation(pattern, self.soup.find('div', class_='user-intro').find('span').text)\n",
    "        return self\n",
    "\n",
    "    def friends(self):\n",
    "        try:\n",
    "            self.followers = re.findall(r'\\d+', self.soup.find('p', class_='rev-link').text)[0]\n",
    "            self.follows = re.findall(r'\\d+', self.soup.find('div', {'id': 'friend'}).a.text)[\n",
    "                0]  # find numbers in string\n",
    "        except IndexError:\n",
    "            self.followers = '0'\n",
    "            self.follows = '0'\n",
    "        return self\n",
    "\n",
    "    def movies(self):\n",
    "        try:\n",
    "            self.watched = re.findall(r'\\d+',\n",
    "                                      self.soup.find('div', {'id': 'movie'}).find('span', class_='pl').find_all('a')[\n",
    "                                          -1].text)[0]\n",
    "        except IndexError:\n",
    "            self.watched = '0'\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class named userprofile, has the same meaning as the name, the functions of the class define basic information, user self introduction, friends and movies list of certain user, they are all parsed from website, so we can use the above codes to get those information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requestsql(sql):\n",
    "    db = MySQLdb.connect(host='localhost', user='root', passwd='12345droeeN', db='testdb', charset='utf8')\n",
    "    cursor = db.cursor()\n",
    "\n",
    "    '''sql = \"INSERT IGNORE INTO testdb.Douban_Movie_Reviews(cid, user_name, movie_code, \\\n",
    "           votes, rate_stars, date, content, add_time) \\\n",
    "           VALUES ('%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s')\" % \\\n",
    "          (cid, username, moviecode, votes, ratestars, Date, content, addtime)'''\n",
    "\n",
    "    try:\n",
    "        # execute sql\n",
    "        cursor.execute(sql)\n",
    "        # submit to database\n",
    "        db.commit()\n",
    "    except:\n",
    "        # Rollback in case there is any error\n",
    "        db.rollback()\n",
    "\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To store and manage mass data, we can use MySQL to manage it, requestsql() defines the connection between Python and SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    loginurl = 'https://www.douban.com/accounts/login?source=main'\n",
    "    username = '1175331160@qq.com'\n",
    "    password = '138droeen'\n",
    "    req, driver = Login(loginurl, username, password)\n",
    "\n",
    "    url = 'https://movie.douban.com/subject/4920389/comments?start=0&limit=20&sort=new_score&status=P'\n",
    "    a = 0\n",
    "    soup = MakeSoup(req, url)\n",
    "\n",
    "    ReviewsNumber = int(soup.find('li', class_='is-active').contents[1].text[3:-1])\n",
    "    for i in range(int(ReviewsNumber / 20)):\n",
    "        moviecode = '3742360' #'4920389'\n",
    "        url = 'https://movie.douban.com/subject/' + \\\n",
    "              moviecode + '/comments?start=' + str(a) + '&limit=20&sort=new_score&status=P'\n",
    "        soup = MakeSoup(req, url)\n",
    "        if len(soup.find_all('div', class_='comment-item')) <= 1:\n",
    "            break\n",
    "        else:\n",
    "            # ReviewDict = {}\n",
    "            for item in soup.find_all('div', class_='comment-item'):\n",
    "                try:\n",
    "                    reviewclass = ReviewContent(item)\n",
    "                    userclass = UserProfile(req, reviewclass.UserUrl)\n",
    "                    # ReviewDict[reviewclass.ReviewID] = reviewclass\n",
    "\n",
    "                    reviewsql = \"INSERT IGNORE INTO testdb.Douban_Movie_Ready_Player_One(cid, user_name, movie_code, \" \\\n",
    "                                \"votes, rate_stars, date, content, add_time) \" \\\n",
    "                                \"VALUES ('%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s')\" % \\\n",
    "                                (reviewclass.ReviewID, reviewclass.UserName, moviecode, reviewclass.Votes,\n",
    "                                 reviewclass.RateStars, reviewclass.Times, reviewclass.Reviews, str(datetime.now()))\n",
    "                    requestsql(reviewsql)\n",
    "\n",
    "                    '''usersql = \"INSERT IGNORE INTO testdb.Douban_Users (user_id, user_name, intro, followers, follow, watched_movies) \" \\\n",
    "                              \"VALUES ('%s', '%s', '%s', '%s', '%s', '%s')\" % \\\n",
    "                              (userclass.basic_info().userid, userclass.basic_info().username,\n",
    "                               userclass.user_intro().intro, userclass.friends().followers,\n",
    "                               userclass.friends().follows, userclass.movies().watched)\n",
    "\n",
    "                    requestsql(usersql)'''\n",
    "                    time.sleep(np.random.uniform(1, 3))\n",
    "\n",
    "\n",
    "                except TypeError:\n",
    "                    pass\n",
    "\n",
    "            a = a + 20\n",
    "            print(a + 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main() defines the usage of above finctions and classes, uses for loop to get all reviews and related users of a movie, time.sleep() is used for mimic the duration of human being behaviors on web searching, hence, we use uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
